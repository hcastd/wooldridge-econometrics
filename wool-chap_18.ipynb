{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Introductory Econometrics: A modern approach***\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 18: Advanced Time Series Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Book: \n",
    "\n",
    "    - WOOLDRIDGE, J. M.. Introdução à econometria: uma abordagem moderna. 3a ed. São Paulo: Pioneira Thomson Learning, 2006.\n",
    "\n",
    "    - WOOLDRIDGE, Jeffrey M. Introductory econometrics: A modern approach. Cengage learning, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LINK to codes correction:\n",
    "\n",
    "http://www.upfie.net/downloads18.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import patsy as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observações iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Processos estocásticos de raízes unitárias: a presença de raíz unitária indica que um choque hoje tenha efeitos duradouros no tempo;\n",
    "\n",
    "- Regressões espúrias: se as duas séries com raízes unitárias forem usadas em uma regressão de uma contra a outra, há grandes chances das estatísticas de testes mostrarem insignificância estatística equivocadamente. Quando os processos estocásticos são integrados em alguma ordem, devemos estar atentos aos procedimentos padrões de inferência;\n",
    "\n",
    "- Com uma combinação linear de séries integradas I(0), a regressão não é espúria, mas pode dizer algo sobre a relação de longo prazo entre as séries. Para esse caso de cointegração, temos um modelo específico conhecido como modelos de correção de erro. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infinite Distributed Lag Models (Modelos de Defasagens Distribuídas)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Uma extensão dos modelos de defasagem distribuídas finitas vistos no capítulos 10 do livro-texto. Permite que as mudanças nos valores das variáveis explicativas afetem todos os valores futuros da variável dependente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y_t = \\alpha + \\delta_0z_t + \\delta_1z_{t-1} + \\delta_2z_{t-2} + .... + u_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trata-se, de séries bivariadas, em que a definição é generalizada, mas que do ponto de vista econômico, nenhuma série se estende infinitamente no futuro.\n",
    "\n",
    "Nesse caso, faz sentido que $\\delta_j \\to 0$ à medida que $t \\to \\infty$. Isso não significa, por exemplo, que há uma regra em que os coeficientes mais pertos do presente devem ser maiores, e sim que, ao longo do tempo, há uma tendência dos efeitos da variável independente sejam reduzidos sobre a variável dependente. Em outras palavras, o passado mais distante da variável dependente tende a ser menos relevante para explicar a variável dependente. \n",
    "\n",
    "Não podemos estimar um modelo com infinitos coeficientes e, ainda, não faria sentido econômico e prático, como dito anteriormente, dado que não temos séries temporais infinitas. Nesse caso, a principal restrição é **limitar o número de parâmetros a serem estimados**. \n",
    "\n",
    "Assim como nos modelos de defasagem finita (FDL), o impacto de um choque em $z$ é $\\delta_0$ se for transitório, mas pode ser a somatória dos $\\delta_j$'s caso o choque em $z$ seja permanente. \n",
    "\n",
    "Nesse caso, o impacto marginal de uma mundança temporária em $z$ para cada período $h \\geq 0$ é dado por:\n",
    "\n",
    "$$\n",
    "E(y_h) = \\alpha + \\delta_h + u_h = \\alpha + \\delta_h\n",
    "$$\n",
    "\n",
    "Com a mesma hipótese de que o erro tem um efeito médio igual a zero. \n",
    "\n",
    "Com um choque temporário e t tendendo a infinito, temos então que o efeito é transitório e se dissipa ao longo do tempo, de modo que $E(y_h) = \\alpha$.\n",
    "\n",
    "Já o impacto de um choque permanente é a soma de todos os coeficientes: \n",
    "\n",
    "$$\n",
    "LRP = \\delta_0 + \\delta_1 + \\delta_2 + ... + \\delta_n\n",
    "$$\n",
    "\n",
    "E na lógica similar ao choque transitório:\n",
    "\n",
    "$$\n",
    "E(y_h) = \\alpha + \\delta_0 + \\delta_1 + \\delta_2 + ... + \\delta_h + u_h = \\alpha + \\delta_0 + \\delta_1 + \\delta_2 + ... + \\delta_h\n",
    "$$\n",
    "\n",
    "Ao assumirmos essas duas formas com um efeito médio do erro igual à zero, trabalhamos também com a hipóteses de **exogeneidade estrita**. Formalmente, as mudanças em $z$ não provocariam mudanças no termo de erro e, formalmente: \n",
    "\n",
    "$$\n",
    "E(u_y|z_{t-2}, ..., z_{t+2}) = 0\n",
    "$$\n",
    "\n",
    "De modo que o erro não depende das variáveis exógenas em nenhum período de tempo. Em aplicações, esse pode ser o caso, mas limita outros casos em que uma mudança na variável exógena hoje seja reflexo de uma mudança na variável endógena no período anterior, principalmente em aplicações relacionadas à política econômica, por exemplo. \n",
    "\n",
    "Para casos como esse, assumimos uma hipótese mais fraca:\n",
    "\n",
    "$$\n",
    "E(u_y|z_t, ..., z_{t-2}) = 0\n",
    "$$\n",
    "\n",
    "Ou seja, fazemos com que o termo do erro não seja correlacionado com as variáveis exógenas apenas no período corrente e nos anteriores, permitindo correlação nos períodos futuros, caso a variável exógena seja alterada em razão dos resultados anteriores da exógena. \n",
    "\n",
    "Vale lembrar que nenhuma das formas dessa hipótese de exogeinedade diz algo sobre a correlação serial. Na verdade, podemos esperar, em boa parte dos casos que haja correlação serial, dado que a equação a ser estimada não necessariamente está completa dinâmicamente. \n",
    "\n",
    "Nesse caso, a interpretação dos impactos temporários e permanentes segue a mesma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defasagem geométrica distribuída - (The Geometric (or Koyck) Distributed Lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\delta_j = \\gamma\\rho^j\n",
    "$$\n",
    "\n",
    "em que: $|\\rho| < 1$ e $j = 1, 2, ...$\n",
    "\n",
    "Lembrando que esse modelo ainda depende de um número infinito de lags.\n",
    "\n",
    "Mas nesse caso, temos que $\\delta_j \\to 0$ quando $j \\to \\infty$ de modo que o tempo passa a ser uma espécie de restrição para a estimação em que o passado distante exerce pouco efeito ou efeito nulo sobre o presente. \n",
    "\n",
    "Para um choque de curto prazo, temos que o impactio é dado por:\n",
    "\n",
    "$$\n",
    "IP = \\delta_0 = \\gamma\n",
    "$$\n",
    "\n",
    "Para choques permanentes, temos um efeito que persiste no tempo e temos a seguinte forma:\n",
    "\n",
    "$$\n",
    "LRP = \\gamma * (1 + \\rho^1 + \\rho^2 + ... + \\rho^j) = \\gamma * \\frac{1}{1 - \\rho} = \\frac{\\gamma}{1 - \\rho}\n",
    "$$\n",
    "\n",
    "Substituindo na primeira equação, temos:\n",
    "\n",
    "$$\n",
    "y_t = \\alpha + \\gamma z_t + \\gamma\\rho z_{t-1} + \\gamma\\rho^2 z_{t-2} + .... + u_t\n",
    "$$\n",
    "\n",
    "e\n",
    "\n",
    "$$\n",
    "y_{t-1} = \\alpha + \\gamma z_{t-1} + \\gamma\\rho z_{t-2} + \\gamma\\rho^2 z_{t-3} + .... + u_{t-1}\n",
    "$$\n",
    "\n",
    "E com a subtração, podemos finalmente estimar um modelo:\n",
    "\n",
    "$$\n",
    "y_t - y_{t-1} = (1-\\rho)\\alpha + \\gamma z_t + u_t -\\rho u_{t-1}\n",
    "$$\n",
    "\n",
    "E manipulando \n",
    "\n",
    "$$\n",
    "y_t = \\alpha_0 + \\gamma z_t + \\rho y_{t-1} + u_t -\\rho u_{t-1}\n",
    "$$\n",
    "\n",
    "Contudo, sem mais hipóteses há grandes chance de termos incosistência nos estimadores dado que o termo do erro composto $v_t = u_t -\\rho u_{t-1}$ será correlacionado com $y_{t-1}$. Ainda, podemos ver que esse erro composto possui correlação serial pela sua forma, que o caracteriza como um processo de média móvel da primeira ordem. \n",
    "\n",
    "Contudo, com a hipótese de exogeneidade estrita, temos que $z$ não estará correlacionado com o termo do erro e, portanto, com um instrumento forte para estimar $y_{t-1}$ poderemos estimar a equação completa. Temos então que o instrumento forte, sob essa hipótese, e a própria defasagem de z: $z_{t-1}$. Basta então obter os erros padrões robustos para correlação serial e teremos estimado o modelo de interesse. \n",
    "\n",
    "Contudo, se o erro seguir um processo AR(1), teremos:\n",
    "\n",
    "$$\n",
    "u_t = \\rho u_{t-1} + e_t \n",
    "$$\n",
    "\n",
    "e, portanto:\n",
    "\n",
    "$$\n",
    "y_t = \\alpha_0 + \\gamma z_t + \\rho y_{t-1} + e_t\n",
    "$$\n",
    "\n",
    "Sob nossa hipótese convencional: $E(u_t|z) = 0$. Assim, a estimação por MQO é consistente e assintóticamente segue normalidade, também com testes válidos de $e_t$ for homoscedástico.\n",
    "\n",
    "Essas propriedades podem ser generalizadas para diversas variáveis exógenas $z_{t1} ... z_{tk}$ e com as hipóteses acima pode ser estimado por MQO ou, caso contrário, estimado por IV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de defasagens racionais distribuídas (Rational Distributed Lag Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além de restringir a distribuição de defasagens, esse modelo permite que os choques produzam efeitos com direções diferentes sobre a variável dependente. \n",
    "\n",
    "Consultar livro texto para mais detalhes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXEMPLO 18.1: Housing Investment and Residential Price Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_koyck: \n",
      "                      b      se       t    pval\n",
      "Intercept       -0.0100  0.0179 -0.5561  0.5814\n",
      "gprice           3.0948  0.9333  3.3159  0.0020\n",
      "linvpc_det_lag1  0.3399  0.1316  2.5831  0.0138\n",
      "\n",
      "table_rational: \n",
      "                      b      se       t    pval\n",
      "Intercept        0.0059  0.0169  0.3466  0.7309\n",
      "gprice           3.2564  0.9703  3.3559  0.0019\n",
      "linvpc_det_lag1  0.5472  0.1517  3.6076  0.0009\n",
      "gprice_lag1     -2.9363  0.9732 -3.0172  0.0047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando dados\n",
    "hseinv = woo.data('hseinv')\n",
    "\n",
    "# Tirando a tendência da variável dependente \n",
    "hseinv['linvpc_detrend'] = sm.tsa.detrend(hseinv['linvpc'])\n",
    "hseinv['gprice_lag1'] = hseinv['gprice'].shift(1)\n",
    "hseinv['linvpc_det_lag1'] = hseinv['linvpc_detrend'].shift(1)\n",
    "\n",
    "# Koyck geometric d.l.:\n",
    "reg_koyck = smf.ols(formula = 'linvpc_detrend ~ gprice + linvpc_det_lag1',\n",
    "                    data = hseinv)\n",
    "results_koyck = reg_koyck.fit()\n",
    "\n",
    "# printando tabela de regressão:\n",
    "table_koyck = pd.DataFrame({'b': round(results_koyck.params, 4),\n",
    "                            'se': round(results_koyck.bse, 4),\n",
    "                            't': round(results_koyck.tvalues, 4),\n",
    "                            'pval': round(results_koyck.pvalues, 4)})\n",
    "print(f'table_koyck: \\n{table_koyck}\\n')\n",
    "\n",
    "# rational d.l.:\n",
    "reg_rational = smf.ols(formula='linvpc_detrend ~ gprice + linvpc_det_lag1 +'\n",
    "                               'gprice_lag1',\n",
    "                       data=hseinv)\n",
    "results_rational = reg_rational.fit()\n",
    "\n",
    "# printando tabela de regressão:\n",
    "table_rational = pd.DataFrame({'b': round(results_rational.params, 4),\n",
    "                               'se': round(results_rational.bse, 4),\n",
    "                               't': round(results_rational.tvalues, 4),\n",
    "                               'pval': round(results_rational.pvalues, 4)})\n",
    "print(f'table_rational: \\n{table_rational}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrp_koyck: 4.68843419476902\n",
      "\n",
      "lrp_rational: 0.7066808046888258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LRP:\n",
    "lrp_koyck = results_koyck.params['gprice'] / (\n",
    "        1 - results_koyck.params['linvpc_det_lag1'])\n",
    "print(f'lrp_koyck: {lrp_koyck}\\n')\n",
    "\n",
    "lrp_rational = (results_rational.params['gprice'] +\n",
    "                results_rational.params['gprice_lag1']) / (\n",
    "                       1 - results_rational.params['linvpc_det_lag1'])\n",
    "print(f'lrp_rational: {lrp_rational}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As diferenças entre GDL e RDL são notáveis, e esse exmplo mostram que a GDL ao ignorar uma defasagem importante na regressão, pode chegar a um resultado muito diferente do método adequado e muitas vezes incompatível com a própria teoria econômica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando para raízes unitárias\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes: \n",
    "\n",
    "1. Dickey-Fuller;\n",
    "\n",
    "2. Augmented Dickey-Fuller. \n",
    "\n",
    "Procedimentos: regressão da primeira diferença da variável endógena com sua primeira defasagem (caso mais simples do teste DF). Ainda, podemos incluir a primeira diferença da defasagem e um número maior de defasagens, levando-nos para o teste DF em sua forma aumentada, ou seja, o teste ADF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 18.4 Unit Root in the Log of U.S. Real Gross Domestic Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table: \n",
      "   names       b      se       t    pval\n",
      "0     x1 -0.2096  0.0866 -2.4207  0.0215\n",
      "1     x2  0.2638  0.1647  1.6010  0.1195\n",
      "2  const  1.6627  0.6717  2.4752  0.0190\n",
      "3     x3  0.0059  0.0027  2.1772  0.0372\n",
      "\n",
      "ADF_stat_aut: -2.420732881476164\n",
      "\n",
      "ADF_pval_aut: 0.36865584571357957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inven = woo.dataWoo('inven')\n",
    "inven['lgdp'] = np.log(inven['gdp'])\n",
    "\n",
    "# automated ADF:\n",
    "res_ADF_aut = sm.tsa.stattools.adfuller(inven['lgdp'], maxlag=1, autolag=None,\n",
    "                                        regression='ct', regresults=True)\n",
    "ADF_stat_aut = res_ADF_aut[0]\n",
    "ADF_pval_aut = res_ADF_aut[1]\n",
    "table = pd.DataFrame({'names': res_ADF_aut[3].resols.model.exog_names,\n",
    "                      'b': np.round(res_ADF_aut[3].resols.params, 4),\n",
    "                      'se': np.round(res_ADF_aut[3].resols.bse, 4),\n",
    "                      't': np.round(res_ADF_aut[3].resols.tvalues, 4),\n",
    "                      'pval': np.round(res_ADF_aut[3].resols.pvalues, 4)})\n",
    "print(f'table: \\n{table}\\n')\n",
    "print(f'ADF_stat_aut: {ADF_stat_aut}\\n')\n",
    "print(f'ADF_pval_aut: {ADF_pval_aut}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão espúria\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além da noção básica da correlação espúria, em que as variáveis y e x podem estar correlacionadas por influência de uma terceria, esse problema se estende À séries temporais.\n",
    "\n",
    "Para STs, a regressão espúria é marcada pela regressão de uma série em outra, geralmente ambas I(1), em que, mesmo sendo séries independentes, há uma correlação identificada na regressão e com as estatísticas de teste indicando haver evidências suficientes para essa correlação. Contudo, por sererm independentes, isso jamais ocorreria. \n",
    "\n",
    "Nesse caso, isso ocorre porque ao utilizarmos as séries em nível, sob a hipótese nula o nosso erro seguiria um processo de passeio aleatório, violando as hipóteses básicas de Guass-Markov e nos levando ao problema da correlação espúria.\n",
    "\n",
    "Por isso, geralmente procedemos com a primeira diferenciação da série, antes de estimar com MQO ou mesmo Variáveis instrumentais. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cointegração e modelos de correção de erro\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cointegração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duas séries I(1) em que suas diferenças são um processo I(0). ***exemplo da taxa de juros de 3 e 6 meses para o tesouro, que quando subtraídas de si, dão o spread***.\n",
    "\n",
    "Podemos testar a cointegração das séries simplesmente definindo a diferença entre elas e usarmos os testes DF ou ADF para verificar a hipótese.\n",
    "\n",
    "Se rejeitarmos a hipótese de que a nova séries é I(1), teremos que a série originada é I(0), vinda de duas séries I(1).\n",
    "\n",
    "Para outra séries em que o parâmetro de cointegração não é observado que incorporamos no termo de erro, podemos testar isolando o termo do erro na equação da regressão e testar com os testes DF e ADF se a séries resultante é I(1) ou I(0). Esse teste também é conhecido como Engle-Granger test.\n",
    "\n",
    "Se as séries forem não cointegradas, a regressão entre elas é espúria e não obtemos nenhuma informação relevante sobre o problema e não há relação de longo prazo entre y e x. Contudo, podemos usar as primeiras diferenças de ambas as séries em uma regressão para tentar identificar sua relação, incluindo defasagens. Mas nesse caso, vale lembrar que essa regressão irá explicar como a diferença em y pode ser explicada por uma diferença em x, não se relacionando com os níveis das variáveis em si. \n",
    "\n",
    "Se a série conter um componente estático (drift), os valores esperados da série são funções lineares do tempo. Nesse caso, podemos esperar ter uma série com tendência estacionária, mas com os parâmetros tornando a série I(0).\n",
    "\n",
    "Podemso testar a cointegração dos componentes de drift com uma regressão que incorpore seus valores no parâmetro estimado e aplicando os testes DF ou ADF sobre os resíduos. Nesse caso, podemos identificar se a nova série, originada de ambas as séries I(1) integradas, possui ou não tendência, mesmo sendo I(0).\n",
    "\n",
    "> DICA: sempre que regredimos uma dessas séries na outra em nível e depois em diferenças e os resultados dos coeficientes e das estatísticas de teste são muito discrepantes, podemos testar para a cointegração.\n",
    "\n",
    "Quando pensamos que as séries são cointegradas, geralmente podemos testar essa hipótese em cima do coeficiente de cointegração. Mas devemos ficar atentos aos impasses relacionados a correlação serial e ausência de exogeneidade estrita, dado que a única exigência para a verificarmos co-integração é de que os erros seja i.i.d e I(0), não havendo nenhum impedimento para esses problemas mencionados. \n",
    "\n",
    "Mas, felizmente esses problemas podem ser corrigidos. O problema da exogeneidade estrita quando regredimos uma dessas séires na outra pode ser corrigido, por exemplo, inserindo a diferenciação da variável dependente junto de sua forma em nível na regressão, por exemplo. Para correlação serial, basta computar os erros padrões robustos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de correção de erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o conceito de cointegração, podemos partir para a abordagem das séries com modelos dinâmicos.\n",
    "\n",
    "Se duas séries não são cointegradas, podemos estimar um modelo dinâmico nas primeiras diferenças e, podemosincluir também, as defasagens das primeiras diferenças.\n",
    "\n",
    "Se as duas séries forem cointegradas, podemos então, adicionar na regressão a nova série da diferença entre ambas que é I(0) e também suas defasagens se for o caso. \n",
    "\n",
    "Dessa forma, um modelo de correção de erro nos permite estudar a dinâmica de curto prazo da relação entre y e x: o termo de correção e erro do modelo tende a puxar o valor de y para o seu equilíbrio a medida que seu erro se distancia da média zero no tempo. \n",
    "\n",
    "Do ponto de vista prático, haverão casos em que esse termo de correção será composto apenas pela diferneça entre os respectivos valores das duas séries ou devemos estimar a regressão, computar os parâmetros de cointegração e o erro, e estimar a segunda regressão com esses dados (Engle-Granger two-step procedure).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50b6e48135b3aa07383f5a96ff512fd2c607c6638df435f7ef5dee28b012c53c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
